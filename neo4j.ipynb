{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config as cfg\n",
    "import json\n",
    "\n",
    "# Load py2neo\n",
    "import py2neo\n",
    "from py2neo import Graph\n",
    "from py2neo.matching import *\n",
    "\n",
    "# Interactive Plotting Libraries\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Plotting Widgets\n",
    "import cufflinks as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Throughput Github Analysis\n",
    "\n",
    "This is a research project led by PhD Simon Goring.\n",
    "\n",
    "Different research questions are tried to be answer such as: \n",
    "\n",
    "- How do individuals and organizations use GitHub (or other public code repositories) to reference, analyze or reuse data from Data Catalogs?\n",
    "\n",
    "- Are there clear patterns of use across public repositories?\n",
    "\n",
    "- Do patterns of use differ by data/disciplinary domain, or do properties of the data resource (presence of an API, online documentation, size of user community) affect patterns of use? \n",
    "\n",
    "- Does the data reuse observed here expand our understanding of current modes of data reuse, e.g. those outlined in https://datascience.codata.org/articles/10.5334/dsj-2017-008/ ?\n",
    "\n",
    "- What are the characteristics and shape of the Earth Science research object network?\n",
    "- What are major nodes of connectivity?\n",
    "- What poorly connected islands exist? \n",
    "- What is the nature of data reuse in this network?\n",
    "- What downstream/second order grant products can be identified from this network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Approach\n",
    "\n",
    "Categorizing a subset of scraped repos, with pre-defined types, which may be updated iteratively as categorization progresses (education, analysis, archiving, informational).\n",
    "\n",
    "\n",
    "Using ML techniques, we might be able to classify repos according to type automatically; and could consider classifying according to repository quality/completeness. Repository quality or completeness would be defined by:\n",
    "\n",
    "- presence/absence/length of readme\n",
    "- number of commits\n",
    "- number of contributors\n",
    "\n",
    "By using neo4j, we can construct and analyze the network graph in order to get:\n",
    "- Centrality and level of connection\n",
    "- Identification of small networks/islands within the network\n",
    "- What databases are highly connected and which are not?\n",
    "- Use database properties (has API, online search portal, has R/Python package, has user forum . . .)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective of the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is going to be used to created an initial Data Exploratory using Neo4j in order to later on, create a Recommendation System using of graph databases. \n",
    "\n",
    "In its initial stages, it might look rough, but this will be improved as it is updated and upgraded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's connect to Neo4j's graph.\n",
    "\n",
    "There is a `config.py` script, imported as `cfg` that includes personal credentials to log into the database. A `config_sample.py` script has been included. There, change the words `username` and `password` accordingly to match your own credentials.\n",
    "\n",
    "The port that neo4j automatically usees is 7687 when working in a local database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Graph\n",
    "graph = Graph(\"bolt://localhost:7687\", auth=(cfg.neo4j['auth']), bolt=True, password=cfg.neo4j['password'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph('bolt://neo4j@localhost:7687', name='neo4j')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select nodes that are a certain kind, we use the command `match`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run queries, you can do `graph.run()` and do the Querie inside quotes. Get data using the verb `.data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': Node('AGENT', homepage='https://github.com/throughput-ec/throughputdb/keywordMgmt', name='Keyword synonymy')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = graph.run(\"MATCH (n:AGENT) RETURN n LIMIT 10\").data()\n",
    "trial[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the nature of nested dictionaries in lists, will definitely represent a challenge when trying to organized data and functions will be needed to make sure each observation's data is appropriately organized in the corresponding features. To convert a list that should be a dictionary use: `json.loads(list_that_should_be_dictionary)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(DISTINCT ocr)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(DISTINCT ocr)\n",
       "0                73563"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run('MATCH (crt:TYPE {type:\"schema:CodeRepository\"})\\\n",
    "           MATCH (crt)<-[:isType]-(ocr:OBJECT) \\\n",
    "           RETURN COUNT(DISTINCT ocr)').to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA to get the right queries\n",
    "\n",
    "In order to figure out how to create a ML model, we need to extract the correct data from the Throughput database.\n",
    "\n",
    "We will analyze and graph the following:\n",
    "- Distribution of references to DBs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note 'Earth Science' databases within graph\n",
    "    - X = DBs; y = # of referenced repos\n",
    "    - Linked repos (x) by commits (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note ES commits \n",
    "    - Linked repos (x) by # of contributors (y)\n",
    "    - Linked repos (x) by # of forks (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting DataCatalogs and Counts(CodeRepos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = graph.run('''MATCH (k:KEYWORD {keyword: \"earth science\"})\\\n",
    "MATCH (k)<-[:hasKeyword]-(:ANNOTATION)-[:Body]->(dc:dataCat)\\\n",
    "MATCH (dc)<-[:Target]-(:ANNOTATION)-[:Target]->(cr:codeRepo)\\\n",
    "RETURN DISTINCT properties(dc), count(DISTINCT cr)''').data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/01_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example on extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r3d100010867'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting ID of Data Catalog\n",
    "counts[1]['properties(dc)']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting number of CodeRepos linked to Data Catalog\n",
    "counts[1]['count(DISTINCT cr)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put DataCatalogs ID's and CodeRepo's counts together\n",
    "\n",
    "helper_dict={'item': [],\n",
    "            'counts':[]}\n",
    "\n",
    "for i in range (0, len(counts)-1):\n",
    "    helper_dict['item'].append(counts[i]['properties(dc)']['id'])\n",
    "    helper_dict['counts'].append(counts[i]['count(DISTINCT cr)'])\n",
    "\n",
    "counts_df = pd.DataFrame(helper_dict)\n",
    "counts_df = counts_df.rename(columns={'item':'dacat', 'counts':'cr_counts'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Other MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph.run('''MATCH (k:KEYWORD {keyword: \"earth science\"})\\\n",
    "MATCH (k)<-[:hasKeyword]-(a1:ANNOTATION)-[:Body]->(dc:dataCat)\\\n",
    "MATCH (dc)<-[:Target]-(a2:ANNOTATION)-[:Target]->(cr:codeRepo)\\\n",
    "RETURN distinct properties(dc), properties(cr)''').data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties(dc)': {'created': 1586832689251,\n",
       "  'name': \"Unidata's RAMADDA\",\n",
       "  'description': \"Our mission is to provide the data services, tools, and cyberinfrastructure leadership that advance earth-system science, enhance educational opportunities, and broaden participation. Unidata's main RAMADDA server (hosted on Unidata's motherlode data server) contains access to a variety of datasets including the full IDD feed, Case Studies and other project data.\",\n",
       "  'id': 'r3d100010356',\n",
       "  'url': 'http://motherlode.ucar.edu/repository'},\n",
       " 'properties(cr)': {'created': 1588852640385,\n",
       "  'meta': '{\"id\": 37471462, \"repo\": \"ramadda\", \"owner\": \"donmurray\", \"name\": \"donmurray/ramadda\", \"url\": \"https://github.com/donmurray/ramadda\", \"created\": \"2015-06-15 (14:49:29.000000)\", \"description\": null, \"topics\": [], \"readme\": {\"readme\": {\"readme\": true, \"badges\": 0, \"headings\": 0, \"char\": 3369}, \"license\": \"Other\"}, \"commits\": {\"totalCommits\": 5604, \"range\": [\"2015-06-09 (01:08:44.000000)\", \"2015-06-13 (12:33:09.000000)\"], \"authors\": [null]}, \"languages\": {\"Java\": 10267669, \"JavaScript\": 1088747, \"HTML\": 958926, \"CSS\": 384048, \"Tcl\": 156286, \"Shell\": 30045, \"Batchfile\": 653, \"Python\": 210}, \"stars\": 0, \"forks\": 0, \"fork\": false, \"issues\": 0, \"branches\": 1, \"watchers\": 0, \"checkdate\": \"2020-11-08 (23:59:26.409711)\"}',\n",
       "  'name': 'donmurray/ramadda',\n",
       "  'description': '',\n",
       "  'id': 37471462,\n",
       "  'url': 'https://github.com/donmurray/ramadda'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = data[0]\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Unidata's RAMADDA\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1['properties(dc)']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1['properties(cr)']['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = dict1['properties(cr)']['meta'] # this is a string, from here, using find and REGEX, get commits \n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = json.loads(string) \n",
    "response['forks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_dict = None\n",
    "helper_dict = {'dacat': [],\n",
    "               'dacat_name': [],\n",
    "               'meta':[],\n",
    "               'cr_item': [],\n",
    "               'cr_name': [],\n",
    "               'forks':[],\n",
    "               'commits':[],\n",
    "               'contributors':[]}\n",
    "\n",
    "for i in range (0, len(data)-1):\n",
    "    helper_dict['dacat'].append(data[i]['properties(dc)']['id'])\n",
    "    helper_dict['dacat_name'].append(data[i]['properties(dc)']['name'])\n",
    "    try:\n",
    "        helper_dict['meta'].append(data[i]['properties(cr)']['meta'])\n",
    "        json_data = json.loads(data[i]['properties(cr)']['meta'])\n",
    "        helper_data = json_data['id']\n",
    "        helper_data_name = json_data['name']\n",
    "        \n",
    "        \n",
    "        # Forks\n",
    "        forks = json_data['forks']\n",
    "        helper_dict['cr_item'].append(helper_data)\n",
    "        helper_dict['cr_name'].append(helper_data_name)\n",
    "        helper_dict['forks'].append(forks)\n",
    "        \n",
    "        # Commits\n",
    "        commits = json_data['commits']['totalCommits']\n",
    "        helper_dict['commits'].append(commits)\n",
    "        \n",
    "        # Contributors \n",
    "        contributors = json_data['commits']['authors']\n",
    "        helper_dict['contributors'].append(len(contributors))\n",
    "        \n",
    "    # Take care of empty spaces.    \n",
    "    except KeyError:\n",
    "        helper_dict['meta'].append(\"None2\")\n",
    "        helper_dict['cr_item'].append(\"Missing\")\n",
    "        helper_dict['cr_name'].append(\"Missing\")\n",
    "        helper_dict['forks'].append(\"Missing\")\n",
    "        helper_dict['commits'].append(\"Missing\")\n",
    "        helper_dict['contributors'].append(\"Missing\")\n",
    "        \n",
    "\n",
    "meta_df = pd.DataFrame(helper_dict)\n",
    "meta_df = meta_df[meta_df['meta'] != \"None2\"]\n",
    "meta_df = meta_df[['dacat', 'dacat_name', 'cr_item', 'cr_name', 'forks', 'commits', 'contributors']]\n",
    "meta_df = meta_df.astype({'cr_item':'str', 'forks': 'int64', 'commits': 'int64', 'contributors': 'int64'})\n",
    "meta_df['cr_item'] = meta_df['cr_item']+'cr'\n",
    "meta_df['dacat'] = meta_df['dacat']+'dc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dacat</th>\n",
       "      <th>dacat_name</th>\n",
       "      <th>cr_item</th>\n",
       "      <th>cr_name</th>\n",
       "      <th>forks</th>\n",
       "      <th>commits</th>\n",
       "      <th>contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r3d100010356dc</td>\n",
       "      <td>Unidata's RAMADDA</td>\n",
       "      <td>37471462cr</td>\n",
       "      <td>donmurray/ramadda</td>\n",
       "      <td>0</td>\n",
       "      <td>5604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r3d100010356dc</td>\n",
       "      <td>Unidata's RAMADDA</td>\n",
       "      <td>44131591cr</td>\n",
       "      <td>CINERGI/TextTeaserOnline</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dacat         dacat_name     cr_item                   cr_name  \\\n",
       "0  r3d100010356dc  Unidata's RAMADDA  37471462cr         donmurray/ramadda   \n",
       "1  r3d100010356dc  Unidata's RAMADDA  44131591cr  CINERGI/TextTeaserOnline   \n",
       "\n",
       "   forks  commits  contributors  \n",
       "0      0     5604             1  \n",
       "1      0        6             1  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dacat</th>\n",
       "      <th>dacat_name</th>\n",
       "      <th>cr_item</th>\n",
       "      <th>cr_name</th>\n",
       "      <th>forks</th>\n",
       "      <th>commits</th>\n",
       "      <th>contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>r3d100010134dc</td>\n",
       "      <td>PANGAEA</td>\n",
       "      <td>229084981cr</td>\n",
       "      <td>dataone-website-test/hugo-and-forestry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.987805</td>\n",
       "      <td>1158.920732</td>\n",
       "      <td>5.463415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.254757</td>\n",
       "      <td>4694.785140</td>\n",
       "      <td>28.739873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>251.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>55881.000000</td>\n",
       "      <td>504.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dacat dacat_name      cr_item  \\\n",
       "count              328        328          328   \n",
       "unique              13         13          319   \n",
       "top     r3d100010134dc    PANGAEA  229084981cr   \n",
       "freq                93         93            3   \n",
       "mean               NaN        NaN          NaN   \n",
       "std                NaN        NaN          NaN   \n",
       "min                NaN        NaN          NaN   \n",
       "25%                NaN        NaN          NaN   \n",
       "50%                NaN        NaN          NaN   \n",
       "75%                NaN        NaN          NaN   \n",
       "max                NaN        NaN          NaN   \n",
       "\n",
       "                                       cr_name       forks       commits  \\\n",
       "count                                      328  328.000000    328.000000   \n",
       "unique                                     319         NaN           NaN   \n",
       "top     dataone-website-test/hugo-and-forestry         NaN           NaN   \n",
       "freq                                         3         NaN           NaN   \n",
       "mean                                       NaN    5.987805   1158.920732   \n",
       "std                                        NaN   29.254757   4694.785140   \n",
       "min                                        NaN    0.000000      1.000000   \n",
       "25%                                        NaN    0.000000     12.000000   \n",
       "50%                                        NaN    0.000000     54.000000   \n",
       "75%                                        NaN    2.000000    251.500000   \n",
       "max                                        NaN  417.000000  55881.000000   \n",
       "\n",
       "        contributors  \n",
       "count     328.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean        5.463415  \n",
       "std        28.739873  \n",
       "min         1.000000  \n",
       "25%         1.000000  \n",
       "50%         2.000000  \n",
       "75%         3.000000  \n",
       "max       504.000000  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting by Data Catalog or Code Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c19f6d8bec1492fbec3aae83dd2ab3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='selection', options=('dacat', 'cr'), value='dacat'), Dropdown(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(x=(0,500))\n",
    "def show_dc_more_than(selection =['dacat','cr'], column=['forks', 'commits', 'contributors'], x = 1):\n",
    "    meta_df\n",
    "    if selection =='dacat':\n",
    "        df = meta_df[['dacat_name', 'cr_item', 'forks', 'commits', 'contributors']]\n",
    "        df = meta_df.groupby('dacat').agg({'dacat_name': 'max', 'cr_item' : 'count', 'forks' : 'sum', 'commits' : 'sum', 'contributors' : 'sum'}).reset_index()\n",
    "        \n",
    "    if selection =='cr':\n",
    "        df = meta_df.groupby('cr_item').agg({'dacat_name': 'max', 'cr_name': 'max', 'forks' : 'sum', 'commits' : 'sum', 'contributors' : 'sum'}).reset_index()\n",
    "        \n",
    "        \n",
    "    \n",
    "    return df.loc[df[column] > x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc74de73e96450781ebb8b2b23e3d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='x', options=('dacat_name', 'cr_name', 'cr_item', 'dacat'), value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def histogram_plot(x = ['dacat_name', 'cr_name', 'cr_item', 'dacat'], \n",
    "                   y = list(meta_df.select_dtypes('int64').columns)[0:],\n",
    "                   filt = widgets.IntSlider(min = 0, max = 100, step = 1, value = 0)):\n",
    "       \n",
    "    if x == 'dacat_name':\n",
    "        grouped_df = meta_df.groupby('dacat_name').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]\n",
    "        \n",
    "    if x == 'cr_name':\n",
    "        grouped_df = meta_df.groupby('cr_name').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]\n",
    "        \n",
    "    if x == 'dacat':\n",
    "        grouped_df = meta_df.groupby('dacat').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]\n",
    "    \n",
    "    if x == 'cr_item':\n",
    "        grouped_df = meta_df.groupby('cr_item').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]       \n",
    "        \n",
    "    # trace\n",
    "    trace = [go.Bar(x=grouped_df[x], y=grouped_df[y])]\n",
    "\n",
    "    # layout\n",
    "    layout = go.Layout(\n",
    "                title = 'Counts plot', # Graph title\n",
    "                xaxis = dict(title = x.title()), # x-axis label\n",
    "                yaxis = dict(title = y.title()), # y-axis label\n",
    "                hovermode ='closest' # handles multiple points landing on the same vertical\n",
    "    )\n",
    "\n",
    "    # fig\n",
    "    fig = go.Figure(trace, layout)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Surprising Data Points for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraodinary Repo over 400 Forks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dacat</th>\n",
       "      <th>dacat_name</th>\n",
       "      <th>cr_item</th>\n",
       "      <th>forks</th>\n",
       "      <th>commits</th>\n",
       "      <th>contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>r3d100011758dc</td>\n",
       "      <td>Nasa's Data Portal</td>\n",
       "      <td>12745174cr</td>\n",
       "      <td>417</td>\n",
       "      <td>55881</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dacat          dacat_name     cr_item  forks  commits  \\\n",
       "302  r3d100011758dc  Nasa's Data Portal  12745174cr    417    55881   \n",
       "\n",
       "     contributors  \n",
       "302           504  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df[meta_df['forks']>300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Catalog it belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dacat</th>\n",
       "      <th>dacat_name</th>\n",
       "      <th>cr_item</th>\n",
       "      <th>forks</th>\n",
       "      <th>commits</th>\n",
       "      <th>contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>r3d100011758dc</td>\n",
       "      <td>Nasa's Data Portal</td>\n",
       "      <td>12745174cr</td>\n",
       "      <td>417</td>\n",
       "      <td>55881</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>r3d100011758dc</td>\n",
       "      <td>Nasa's Data Portal</td>\n",
       "      <td>33125718cr</td>\n",
       "      <td>142</td>\n",
       "      <td>12237</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>r3d100011758dc</td>\n",
       "      <td>Nasa's Data Portal</td>\n",
       "      <td>90807748cr</td>\n",
       "      <td>79</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dacat          dacat_name     cr_item  forks  commits  \\\n",
       "302  r3d100011758dc  Nasa's Data Portal  12745174cr    417    55881   \n",
       "314  r3d100011758dc  Nasa's Data Portal  33125718cr    142    12237   \n",
       "328  r3d100011758dc  Nasa's Data Portal  90807748cr     79      112   \n",
       "\n",
       "     contributors  \n",
       "302           504  \n",
       "314             3  \n",
       "328             2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df[(meta_df['dacat']=='r3d100011758dc') & (meta_df['forks']>50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis checking for Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data = graph.run('''MATCH (s:SUBJECT)\\\n",
    "WHERE s.id IN [313, 314, 315, 317]\\\n",
    "MATCH (s)<-[:hasSubject]-(a:ANNOTATION)-[]->(dc:dataCat)\\\n",
    "MATCH (dc)<-[:Target]-(:ANNOTATION)-[:Target]->(cr:codeRepo)\\\n",
    "RETURN distinct properties(dc), properties(cr), s.id''').data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df():\n",
    "    helper_dict = None\n",
    "    subject_dict = {'313': 'Atmospheric Science, Oceanography and Climate Research',\n",
    "                '314': 'Geology and Palaeontology',\n",
    "                '315': 'Geophysics and Geodesy',\n",
    "                '317': 'Geography'}\n",
    "    \n",
    "    helper_dict = {'dacat': [],\n",
    "                   'dacat_name':[],\n",
    "                   'meta':[],\n",
    "                   'cr_item': [],\n",
    "                   'cr_name': [],\n",
    "                   'forks':[],\n",
    "                   'commits':[],\n",
    "                   'contributors':[],\n",
    "                   'subject':[]}\n",
    "\n",
    "    for i in range (0, len(data)-1):\n",
    "        helper_dict['dacat'].append(subject_data[i]['properties(dc)']['id'])\n",
    "        helper_dict['dacat_name'].append(data[i]['properties(dc)']['name'])\n",
    "        helper_dict['subject'].append(subject_data[i]['s.id'])\n",
    "\n",
    "        try:\n",
    "            helper_dict['meta'].append(subject_data[i]['properties(cr)']['meta'])\n",
    "            json_data = json.loads(subject_data[i]['properties(cr)']['meta'])\n",
    "            helper_data = json_data['id']\n",
    "            helper_data_name = json_data['name']\n",
    "\n",
    "            # Forks\n",
    "            forks = json_data['forks']\n",
    "            helper_dict['cr_item'].append(helper_data)\n",
    "            helper_dict['cr_name'].append(helper_data_name)\n",
    "            helper_dict['forks'].append(forks)\n",
    "\n",
    "            # Commits\n",
    "            commits = json_data['commits']['totalCommits']\n",
    "            helper_dict['commits'].append(commits)\n",
    "\n",
    "            # Contributors \n",
    "            contributors = json_data['commits']['authors']\n",
    "            helper_dict['contributors'].append(len(contributors))\n",
    "\n",
    "        # Take care of empty spaces.    \n",
    "        except KeyError:\n",
    "            helper_dict['meta'].append(\"None2\")\n",
    "            helper_dict['cr_item'].append(\"Missing\")\n",
    "            helper_dict['cr_name'].append(\"Missing\")\n",
    "            helper_dict['forks'].append(\"Missing\")\n",
    "            helper_dict['commits'].append(\"Missing\")\n",
    "            helper_dict['contributors'].append(\"Missing\")\n",
    "\n",
    "\n",
    "    meta_df = pd.DataFrame(helper_dict)\n",
    "    meta_df = meta_df[meta_df['meta'] != \"None2\"]\n",
    "    meta_df = meta_df[['dacat', 'dacat_name', 'cr_item', 'cr_name', 'forks', 'commits', 'contributors', 'subject']]\n",
    "    meta_df = meta_df.astype({'cr_item':'str', 'forks': 'int64', 'commits': 'int64', 'contributors': 'int64', 'subject':'str'})\n",
    "    meta_df['cr_item'] = meta_df['cr_item']+'cr'\n",
    "    meta_df['dacat'] = meta_df['dacat']+'dc'\n",
    "    meta_df['subject_str'] = meta_df['subject'].map(subject_dict)\n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df_subject = create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dacat</th>\n",
       "      <th>dacat_name</th>\n",
       "      <th>cr_item</th>\n",
       "      <th>cr_name</th>\n",
       "      <th>forks</th>\n",
       "      <th>commits</th>\n",
       "      <th>contributors</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>r3d100011290dc</td>\n",
       "      <td>Comprehensive Large Array-data Stewardship System</td>\n",
       "      <td>260025976cr</td>\n",
       "      <td>rjmalka/Unit4_Springboard</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>r3d100011290dc</td>\n",
       "      <td>Comprehensive Large Array-data Stewardship System</td>\n",
       "      <td>257601085cr</td>\n",
       "      <td>lokesh-1998/London_HousingPrices</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>r3d100011290dc</td>\n",
       "      <td>Comprehensive Large Array-data Stewardship System</td>\n",
       "      <td>70050572cr</td>\n",
       "      <td>rauldiazpoblete/notes</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>2</td>\n",
       "      <td>317</td>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>r3d100011290dc</td>\n",
       "      <td>Comprehensive Large Array-data Stewardship System</td>\n",
       "      <td>227422282cr</td>\n",
       "      <td>jasdalucl2018/CASA_Assignment_2019</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>r3d100011290dc</td>\n",
       "      <td>Comprehensive Large Array-data Stewardship System</td>\n",
       "      <td>259462062cr</td>\n",
       "      <td>joew1234/Springboard-London-housing-case-study</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>r3d100012894dc</td>\n",
       "      <td>Nasa's Data Portal</td>\n",
       "      <td>193558412cr</td>\n",
       "      <td>earthcubearchitecture-project418/CDFSemanticNe...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>Geophysics and Geodesy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>r3d100012894dc</td>\n",
       "      <td>Nasa's Data Portal</td>\n",
       "      <td>193558412cr</td>\n",
       "      <td>earthcubearchitecture-project418/CDFSemanticNe...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>Geology and Palaeontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>r3d100012894dc</td>\n",
       "      <td>Nasa's Data Portal</td>\n",
       "      <td>78788586cr</td>\n",
       "      <td>rdiersing1/FuzzyNameMatching</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>Geography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>r3d100012894dc</td>\n",
       "      <td>Nasa's Data Portal</td>\n",
       "      <td>78788586cr</td>\n",
       "      <td>rdiersing1/FuzzyNameMatching</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>315</td>\n",
       "      <td>Geophysics and Geodesy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>r3d100012894dc</td>\n",
       "      <td>Nasa's Data Portal</td>\n",
       "      <td>78788586cr</td>\n",
       "      <td>rdiersing1/FuzzyNameMatching</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>Geology and Palaeontology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dacat                                         dacat_name  \\\n",
       "15   r3d100011290dc  Comprehensive Large Array-data Stewardship System   \n",
       "18   r3d100011290dc  Comprehensive Large Array-data Stewardship System   \n",
       "22   r3d100011290dc  Comprehensive Large Array-data Stewardship System   \n",
       "25   r3d100011290dc  Comprehensive Large Array-data Stewardship System   \n",
       "39   r3d100011290dc  Comprehensive Large Array-data Stewardship System   \n",
       "..              ...                                                ...   \n",
       "332  r3d100012894dc                                 Nasa's Data Portal   \n",
       "333  r3d100012894dc                                 Nasa's Data Portal   \n",
       "334  r3d100012894dc                                 Nasa's Data Portal   \n",
       "335  r3d100012894dc                                 Nasa's Data Portal   \n",
       "336  r3d100012894dc                                 Nasa's Data Portal   \n",
       "\n",
       "         cr_item                                            cr_name  forks  \\\n",
       "15   260025976cr                          rjmalka/Unit4_Springboard      0   \n",
       "18   257601085cr                   lokesh-1998/London_HousingPrices      0   \n",
       "22    70050572cr                              rauldiazpoblete/notes      0   \n",
       "25   227422282cr                 jasdalucl2018/CASA_Assignment_2019      0   \n",
       "39   259462062cr     joew1234/Springboard-London-housing-case-study      0   \n",
       "..           ...                                                ...    ...   \n",
       "332  193558412cr  earthcubearchitecture-project418/CDFSemanticNe...      0   \n",
       "333  193558412cr  earthcubearchitecture-project418/CDFSemanticNe...      0   \n",
       "334   78788586cr                       rdiersing1/FuzzyNameMatching      0   \n",
       "335   78788586cr                       rdiersing1/FuzzyNameMatching      0   \n",
       "336   78788586cr                       rdiersing1/FuzzyNameMatching      0   \n",
       "\n",
       "     commits  contributors subject                subject_str  \n",
       "15         2             1     317                  Geography  \n",
       "18         2             1     317                  Geography  \n",
       "22       154             2     317                  Geography  \n",
       "25        36             1     317                  Geography  \n",
       "39         2             1     317                  Geography  \n",
       "..       ...           ...     ...                        ...  \n",
       "332       19             1     315     Geophysics and Geodesy  \n",
       "333       19             1     314  Geology and Palaeontology  \n",
       "334       18             1     317                  Geography  \n",
       "335       18             1     315     Geophysics and Geodesy  \n",
       "336       18             1     314  Geology and Palaeontology  \n",
       "\n",
       "[92 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_df_subject.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e9cadae72d4529b0cfa54eaee7389b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='value', options=('Geophysics and Geodesy', 'Geology and Palaeontol…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(x=(0,50))\n",
    "def show_df(value = list(set(meta_df_subject['subject_str'])), \n",
    "            selection =['dacat_name', 'dacat','cr', 'cr_name'], \n",
    "            column=['forks', 'commits', 'contributors'], \n",
    "            x = 1):\n",
    "   \n",
    "    df = meta_df_subject[meta_df_subject['subject_str'] == value]\n",
    "    \n",
    "    df = pd.DataFrame(df, columns=['dacat', 'dacat_name', 'cr_item', 'cr_name', 'forks', 'commits', 'contributors', 'subject', 'subject_str'])\n",
    "     \n",
    "    if selection == 'dacat_name':\n",
    "        df = df.groupby('dacat_name').agg({'dacat': 'max', 'cr_item' : 'count', 'forks' : 'sum', 'commits' : 'sum', 'contributors' : 'sum'}).reset_index()\n",
    "        df2 = df[['dacat', 'dacat_name', 'cr_item', 'forks', 'commits', 'contributors']]\n",
    "        \n",
    "    if selection =='dacat':\n",
    "        df = df.groupby('dacat').agg({'dacat_name': 'max', 'cr_item' : 'count', 'forks' : 'sum', 'commits' : 'sum', 'contributors' : 'sum'}).reset_index()\n",
    "        df2 = df[['dacat', 'dacat_name', 'cr_item', 'forks', 'commits', 'contributors']]\n",
    "        \n",
    "    if selection =='cr':\n",
    "        df = df.groupby('cr_item').agg({'dacat_name': 'max', 'cr_name': 'max', 'forks' : 'sum', 'commits' : 'sum', 'contributors' : 'sum'}).reset_index()\n",
    "        df2 = df[['cr_item', 'dacat_name', 'forks', 'commits', 'contributors']] \n",
    "    \n",
    "    if selection =='cr_name':\n",
    "        df = df.groupby('cr_name').agg({'dacat_name': 'max', 'cr_item': 'max', 'forks' : 'sum', 'commits' : 'sum', 'contributors' : 'sum'}).reset_index()\n",
    "        df2 = df[['cr_name', 'cr_item', 'dacat_name', 'forks', 'commits', 'contributors']] \n",
    "           \n",
    "    return df2.loc[df2[column] >= x]\n",
    "\n",
    "# Default sort on Number of Commits\n",
    "# Add Catalog Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aaa7b8f2d20485392bae44cbf551e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='x', options=('dacat_name', 'cr_name'), value='dacat_name'), Dropdo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def histogram_plot(x = ['dacat_name', 'cr_name'], \n",
    "                   y = list(meta_df_subject.select_dtypes('int64').columns)[0:],\n",
    "                   subject_id = list(set(meta_df_subject['subject_str'])),\n",
    "                   filt = widgets.IntSlider(min = 0, max = 50, step = 1, value = 0)):\n",
    "    \n",
    "    df = meta_df_subject[meta_df_subject['subject_str']==subject_id]\n",
    "    \n",
    "    if x == 'dacat_name':\n",
    "        grouped_df = df.groupby('dacat_name').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]\n",
    "    \n",
    "    if x == 'cr_name':\n",
    "        grouped_df = df.groupby('cr_name').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]\n",
    "        \n",
    "    \n",
    "    # trace\n",
    "    trace = [go.Bar(x=grouped_df[x], y=grouped_df[y])]\n",
    "\n",
    "    # layout\n",
    "    layout = go.Layout(\n",
    "                title = 'Counts plot', # Graph title\n",
    "                xaxis = dict(title = x.title()), # x-axis label\n",
    "                yaxis = dict(title = y.title()), # y-axis label\n",
    "                hovermode ='closest' # handles multiple points landing on the same vertical\n",
    "    )\n",
    "\n",
    "    # fig\n",
    "    fig = go.Figure(trace, layout)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img2](img/subject_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Green: Data Cat\n",
    "Navy blue: subject\n",
    "Pink: Code Repo\n",
    "Ligh Blue: Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Data Without Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = graph.run('''MATCH ()<-[:hasSubject]-(a:ANNOTATION)-[]->(dc:dataCat)\\\n",
    "MATCH (dc)<-[:Target]-(:ANNOTATION)-[:Target]->(cr:codeRepo)\\\n",
    "RETURN distinct properties(dc), properties(cr)''').data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57693"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties(dc)': {'created': 1586832657305,\n",
       "  'contact': 'https://earthquake.usgs.gov/contactus/',\n",
       "  'name': 'National Earthquake Information Center',\n",
       "  'description': \"The mission of the National Earthquake Information Center (NEIC) is to determine rapidly the location and size of all destructive earthquakes worldwide and to immediately disseminate this information to concerned national and international agencies, scientists, and the general public. The NEIC compiles and maintains an extensive, global seismic database on earthquake parameters and their effects that serves as a solid foundation for basic and applied earth science research.\\nThe NEIC maintained until 2012 the former 'World Data Center for Seismology'.\",\n",
       "  'id': 'r3d100010313',\n",
       "  'url': 'https://earthquake.usgs.gov/contactus/golden/neic.php'},\n",
       " 'properties(cr)': {'meta': '{\"id\": 247252173, \"repo\": \"wikipedia.ko\", \"owner\": \"chinapedia\", \"name\": \"chinapedia/wikipedia.ko\", \"url\": \"https://github.com/chinapedia/wikipedia.ko\", \"created\": \"2020-03-14 (10:02:09.000000)\", \"description\": \"\\\\ud55c\\\\uad6d\\\\uc5b4 Wikipedia https://ko.wikipedia.org/ on GitHub \", \"topics\": [], \"readme\": {\"readme\": {\"readme\": true, \"badges\": 0, \"headings\": 0, \"char\": 234}, \"license\": null}, \"commits\": {\"totalCommits\": 326, \"range\": [\"2020-10-16 (15:43:40.000000)\", \"2020-10-25 (02:23:52.000000)\"], \"authors\": [\"liruqi\"]}, \"languages\": {\"message\": \"API rate limit exceeded for 128.104.50.58. (But here\\'s the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\", \"documentation_url\": \"https://developer.github.com/v3/#rate-limiting\"}, \"stars\": 1, \"forks\": 0, \"fork\": false, \"issues\": 0, \"branches\": 1, \"watchers\": 1, \"checkdate\": \"2020-11-06 (18:11:26.448414)\"}',\n",
       "  'created': 1588077870903,\n",
       "  'name': 'chinapedia/wikipedia.ko',\n",
       "  'description': '한국어 Wikipedia https://ko.wikipedia.org/ on GitHub ',\n",
       "  'id': 247252173,\n",
       "  'url': 'https://github.com/chinapedia/wikipedia.ko'}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_dict = None\n",
    "helper_dict = {'dacat': [],\n",
    "               'dacat_name':[],\n",
    "               'meta':[],\n",
    "               'cr_item': [],\n",
    "               'cr_name': [],\n",
    "               'forks':[],\n",
    "               'commits':[],\n",
    "               'contributors':[]}\n",
    "\n",
    "for i in range (0, len(all_data)-1):\n",
    "    helper_dict['dacat'].append(all_data[i]['properties(dc)']['id'])\n",
    "    helper_dict['dacat_name'].append(all_data[i]['properties(dc)']['name'])\n",
    "    \n",
    "    try:\n",
    "        helper_dict['meta'].append(all_data[i]['properties(cr)']['meta'])\n",
    "        json_data = json.loads(all_data[i]['properties(cr)']['meta'])\n",
    "        helper_data = json_data['id']\n",
    "        helper_data_name = json_data['name']\n",
    "        \n",
    "        # Forks\n",
    "        forks = json_data['forks']\n",
    "        helper_dict['cr_item'].append(helper_data)\n",
    "        helper_dict['cr_name'].append(helper_data_name)\n",
    "        helper_dict['forks'].append(forks)\n",
    "        \n",
    "        # Commits\n",
    "        commits = json_data['commits']['totalCommits']\n",
    "        helper_dict['commits'].append(commits)\n",
    "        \n",
    "        # Contributors \n",
    "        contributors = json_data['commits']['authors']\n",
    "        helper_dict['contributors'].append(len(contributors))\n",
    "        \n",
    "    # Take care of empty spaces.    \n",
    "    except KeyError:\n",
    "        helper_dict['meta'].append(\"None2\")\n",
    "        helper_dict['cr_item'].append(\"Missing\")\n",
    "        helper_dict['cr_name'].append(\"Missing\")\n",
    "        helper_dict['forks'].append(\"Missing\")\n",
    "        helper_dict['commits'].append(\"Missing\")\n",
    "        helper_dict['contributors'].append(\"Missing\")\n",
    "        \n",
    "\n",
    "meta_df = pd.DataFrame(helper_dict)\n",
    "meta_df = meta_df[meta_df['meta'] != \"None2\"]\n",
    "meta_df = meta_df[['dacat', 'dacat_name', 'cr_item', 'cr_name', 'forks', 'commits', 'contributors']]\n",
    "meta_df = meta_df.astype({'cr_item':'str', 'forks': 'int64', 'commits': 'int64', 'contributors': 'int64'})\n",
    "meta_df['cr_item'] = meta_df['cr_item']+'cr'\n",
    "meta_df['dacat'] = meta_df['dacat']+'dc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dacat</th>\n",
       "      <th>dacat_name</th>\n",
       "      <th>cr_item</th>\n",
       "      <th>cr_name</th>\n",
       "      <th>forks</th>\n",
       "      <th>commits</th>\n",
       "      <th>contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r3d100010313dc</td>\n",
       "      <td>National Earthquake Information Center</td>\n",
       "      <td>247252173cr</td>\n",
       "      <td>chinapedia/wikipedia.ko</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r3d100010313dc</td>\n",
       "      <td>National Earthquake Information Center</td>\n",
       "      <td>18522395cr</td>\n",
       "      <td>usgs/earthquake-website</td>\n",
       "      <td>54</td>\n",
       "      <td>3641</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r3d100010313dc</td>\n",
       "      <td>National Earthquake Information Center</td>\n",
       "      <td>94204283cr</td>\n",
       "      <td>ttsteiger/ttsteiger.github.io</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r3d100010313dc</td>\n",
       "      <td>National Earthquake Information Center</td>\n",
       "      <td>84948908cr</td>\n",
       "      <td>ttsteiger/Udacity_DAND</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r3d100010313dc</td>\n",
       "      <td>National Earthquake Information Center</td>\n",
       "      <td>69878384cr</td>\n",
       "      <td>usgs/neic-locator</td>\n",
       "      <td>6</td>\n",
       "      <td>273</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57675</th>\n",
       "      <td>r3d100010268dc</td>\n",
       "      <td>Incorporated Research Institutions for Seismology</td>\n",
       "      <td>67154115cr</td>\n",
       "      <td>jallen2/Research-Trend</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57676</th>\n",
       "      <td>r3d100010268dc</td>\n",
       "      <td>Incorporated Research Institutions for Seismology</td>\n",
       "      <td>52891387cr</td>\n",
       "      <td>iris-edu/stationxml-validator</td>\n",
       "      <td>7</td>\n",
       "      <td>420</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57677</th>\n",
       "      <td>r3d100010268dc</td>\n",
       "      <td>Incorporated Research Institutions for Seismology</td>\n",
       "      <td>56903665cr</td>\n",
       "      <td>iris-edu-int/ispaq</td>\n",
       "      <td>5</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57683</th>\n",
       "      <td>r3d100010269dc</td>\n",
       "      <td>J. Craig Venter Institute</td>\n",
       "      <td>116506085cr</td>\n",
       "      <td>poldham/blog</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57685</th>\n",
       "      <td>r3d100010269dc</td>\n",
       "      <td>J. Craig Venter Institute</td>\n",
       "      <td>224878770cr</td>\n",
       "      <td>YulongNiu/YulongNiu.github.io</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15685 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dacat                                         dacat_name  \\\n",
       "0      r3d100010313dc             National Earthquake Information Center   \n",
       "1      r3d100010313dc             National Earthquake Information Center   \n",
       "2      r3d100010313dc             National Earthquake Information Center   \n",
       "3      r3d100010313dc             National Earthquake Information Center   \n",
       "4      r3d100010313dc             National Earthquake Information Center   \n",
       "...               ...                                                ...   \n",
       "57675  r3d100010268dc  Incorporated Research Institutions for Seismology   \n",
       "57676  r3d100010268dc  Incorporated Research Institutions for Seismology   \n",
       "57677  r3d100010268dc  Incorporated Research Institutions for Seismology   \n",
       "57683  r3d100010269dc                          J. Craig Venter Institute   \n",
       "57685  r3d100010269dc                          J. Craig Venter Institute   \n",
       "\n",
       "           cr_item                        cr_name  forks  commits  \\\n",
       "0      247252173cr        chinapedia/wikipedia.ko      0      326   \n",
       "1       18522395cr        usgs/earthquake-website     54     3641   \n",
       "2       94204283cr  ttsteiger/ttsteiger.github.io      0      102   \n",
       "3       84948908cr         ttsteiger/Udacity_DAND      0       87   \n",
       "4       69878384cr              usgs/neic-locator      6      273   \n",
       "...            ...                            ...    ...      ...   \n",
       "57675   67154115cr         jallen2/Research-Trend      6       42   \n",
       "57676   52891387cr  iris-edu/stationxml-validator      7      420   \n",
       "57677   56903665cr             iris-edu-int/ispaq      5      220   \n",
       "57683  116506085cr                   poldham/blog      3       71   \n",
       "57685  224878770cr  YulongNiu/YulongNiu.github.io      0       12   \n",
       "\n",
       "       contributors  \n",
       "0                 1  \n",
       "1                29  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 7  \n",
       "...             ...  \n",
       "57675             3  \n",
       "57676             7  \n",
       "57677             3  \n",
       "57683             1  \n",
       "57685             1  \n",
       "\n",
       "[15685 rows x 7 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7b812380bf45d1b2f7ab4c86bba719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='x', options=('dacat_name', 'cr_name', 'cr_item', 'dacat'), value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def histogram_plot(x = ['dacat_name', 'cr_name', 'cr_item', 'dacat'], \n",
    "                   y = list(meta_df.select_dtypes('int64').columns)[0:], \n",
    "                   filt = widgets.IntSlider(min = 0, max = 3000, step = 1, value = 50)):\n",
    "       \n",
    "    if x == 'dacat_name':\n",
    "        grouped_df = meta_df.groupby('dacat_name').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]\n",
    "    \n",
    "    if x == 'cr_name':\n",
    "        grouped_df = meta_df.groupby('cr_name').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]     \n",
    "        \n",
    "    if x == 'dacat':\n",
    "        grouped_df = meta_df.groupby('dacat').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]\n",
    "    \n",
    "    if x == 'cr_item':\n",
    "        grouped_df = meta_df.groupby('cr_item').sum().reset_index()\n",
    "        grouped_df = grouped_df[grouped_df[y] > filt]     \n",
    "        \n",
    "    # trace\n",
    "    trace = [go.Bar(x=grouped_df[x], y=grouped_df[y])]\n",
    "\n",
    "    # layout\n",
    "    layout = go.Layout(\n",
    "                title = 'Counts plot', # Graph title\n",
    "                xaxis = dict(title = x.title()), # x-axis label\n",
    "                yaxis = dict(title = y.title()), # y-axis label\n",
    "                hovermode ='closest' # handles multiple points landing on the same vertical\n",
    "    )\n",
    "\n",
    "    # fig\n",
    "    fig = go.Figure(trace, layout)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
